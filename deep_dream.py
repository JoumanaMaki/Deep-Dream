# -*- coding: utf-8 -*-
"""Deep Dream.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RZZBZHNBVO8vh7NDUFUCssFVqVeUKd4e

#Deep Dream

## Importing libraries
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

"""## Load pre-build concolutional neural network"""

base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet') #include_top=False : means do not take the dense layer only the convolutional and pooling layers

base_model.summary()

len(base_model.layers)

#Relu (negative returns 0, otherwise result is the nb itself)
#names = ['mixed3','mixed5','mixed8', 'mixed9']
names = ['mixed3','mixed5']

layers = [base_model.get_layer(name).output for name in names]

layers

deep_dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)

deep_dream_model.summary()

"""## Loading the pre-processing the image"""

from google.colab import drive
drive.mount('/content/drive')

image = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/Computer Vision Masterclass/Images/StaryNight.jpg', target_size=(225,375))

plt.imshow(image)

type(image)

image.size

image.mode

len(image.mode)

list(image.getdata()) #see pixels of the image

#convert to numpy format to be able to work with tensorflow
image = tf.keras.preprocessing.image.img_to_array(image)

image, type(image)

image.shape #with pil library we need to tyoe image.size to see the shape of the image

image.min(), image.max()

#we need to normalize the number or the neural network will take a very ling timw to process the images
#image = image / 255 : we are not using this method because we are using the inception_v3
image = tf.keras.applications.inception_v3.preprocess_input(image) # all the pixels of the image will the pre-processed according the same pre-processing that was made in the original paper for the original architecture

image

image.min(), image.max() # in the inception net the values are from -1 to 1 and not 0 to 1

"""## Getting the activations"""

image.shape

#we need to put the variable in the batch format as we have only one image that are going to send to the Neural network , we need an additional 1
image_batch = tf.expand_dims(image, axis=0)

image_batch.shape

activations = deep_dream_model.predict(image_batch)

deep_dream_model.outputs

len(activations)

activations[0] # for mixed 3

activations[0].shape, activations[1].shape

"""## Calculating the loss"""

def calculate_loss(image, network):
  image_batch = tf.expand_dims(image, axis=0)
  #activations = network.predict(image_batch)
  activations = network(image_batch)
  losses = []
  for activation in activations:
    loss = tf.math.reduce_mean(activation)
    losses.append(loss)
    # print(losses)
    # print(np.shape(losses))
  total_loss = tf.reduce_sum(losses)
  return total_loss

calculate_loss(image, deep_dream_model)

"""## Gradient ascent"""

#traditional neural network : minimize loss with gradient descent
# deep dream is to maximize the loss ( we emphasize the part of the image)
# deep dream also changes the pixels of the input image
@tf.function
def deep_dream(network, image, learning_rate):
  with tf.GradientTape() as tape:
    tape.watch(image)
    loss = calculate_loss(image, network)
  gradients = tape.gradient(loss, image) #tensorflow function to calculate the derivative
  gradients /= tf.math.reduce_std(gradients)

  image += learning_rate * gradients
  image = tf.clip_by_value(image, -1, 1) # normalize the images
  return loss, image

def inverse_transform(image):
  image = 255 * (image + 1.0) / 2.0 # to see the image with matplotlib we need the original format of the image
  return tf.cast(image, tf.uint8)

def run_deep_dream(network, image, epochs, learning_rate):
  for epoch in range(epochs):
    loss, image = deep_dream(network, image, learning_rate)
    if epoch % 200 == 0:
      plt.figure(figsize=(12,12))
      plt.imshow(inverse_transform(image))
      plt.show()
      print(f"Epoch {epoch} loss: {loss}")

"""##Generating images"""

image.shape

type(image)

run_deep_dream(deep_dream_model, image, 8000, 0.001)

image = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/Computer Vision Masterclass/Images/sky.jpeg',
                                              target_size = (225, 375))

image = tf.keras.preprocessing.image.img_to_array(image)
image = tf.keras.applications.inception_v3.preprocess_input(image)

run_deep_dream(network = deep_dream_model, image = image, epochs = 8000, learning_rate = 0.0001)

